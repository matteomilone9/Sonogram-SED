{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T23:42:40.772539Z",
     "start_time": "2025-08-19T23:42:40.759285Z"
    }
   },
   "source": [
    "import warnings\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import csv\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from aed_models import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T23:42:41.842140Z",
     "start_time": "2025-08-19T23:42:41.834405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === PARAMETRI MODELLO ===\n",
    "sample_rate = 16000\n",
    "duration = 1\n",
    "seg_len = sample_rate * duration\n",
    "threshold = 0.0020"
   ],
   "id": "d3701731050a306e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T23:42:43.447771Z",
     "start_time": "2025-08-19T23:42:43.148123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === FUNZIONI ===\n",
    "def load_audio(file_like, target_length=seg_len):\n",
    "    waveform, sr = torchaudio.load(file_like)\n",
    "    if sr != sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    original_length = waveform.shape[1]  # Lunghezza in campioni\n",
    "\n",
    "    # Padding o trimming\n",
    "    if original_length > target_length:\n",
    "        waveform = waveform[:, :target_length]\n",
    "        original_length = target_length\n",
    "    else:\n",
    "        pad_len = target_length - original_length\n",
    "        waveform = F.pad(waveform, (0, pad_len))\n",
    "\n",
    "    return waveform.squeeze(0), original_length  # [160000], valore reale\n",
    "\n",
    "\n",
    "def run_inference(model, audio_tensor, original_length, threshold=threshold):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    model.transform_tf = model.transform_tf.to(device)\n",
    "\n",
    "    audio_tensor = audio_tensor.unsqueeze(0).to(device)  # [1, 160000]\n",
    "    feature_vector = model.preprocessing(audio_tensor)   # [1, T, 640]\n",
    "\n",
    "    # Calcolo numero di frame reali\n",
    "    hop_length = model.transform_tf.hop_length\n",
    "    real_t_bins = 1 + (original_length // hop_length)\n",
    "    real_vector_array_size = real_t_bins - model.frames + 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded = model.encoder(feature_vector)\n",
    "        bottleneck = model.bottleneck(encoded)\n",
    "        reconstructed = model.decoder(bottleneck)\n",
    "\n",
    "    # Taglio alla lunghezza effettiva in feature (T)\n",
    "    feature_vector = feature_vector[:, :real_vector_array_size, :]\n",
    "    reconstructed = reconstructed[:, :real_vector_array_size, :]\n",
    "\n",
    "    # Calcolo errore\n",
    "    loss = F.mse_loss(reconstructed, feature_vector).item()\n",
    "    return feature_vector.cpu(), reconstructed.cpu(), loss\n",
    "\n",
    "\n",
    "def analyze_in_memory(url, username, password, model):\n",
    "    resp = requests.get(url, auth=HTTPBasicAuth(username, password), stream=True)\n",
    "    resp.raise_for_status()\n",
    "    audio_data = io.BytesIO(resp.content)\n",
    "\n",
    "    waveform, real_samples = load_audio(audio_data)\n",
    "    _, _, loss = run_inference(model, waveform, real_samples)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def list_links(url, username, password):\n",
    "    print(f\"Listo i link da: {url}\")\n",
    "    resp = requests.get(url, auth=HTTPBasicAuth(username, password))\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "    print(f\"Link trovati: {links}\")\n",
    "    return links\n",
    "\n",
    "def gather_audio_urls(base_url, username, password):\n",
    "    urls = []\n",
    "    links = list_links(base_url, username, password)\n",
    "\n",
    "    # Aggiunta 1: cerca direttamente i file FLAC in base_url\n",
    "    for href in links:\n",
    "        if href.lower().endswith(('.wav', '.flac')):\n",
    "            urls.append(urljoin(base_url + \"/\", href))\n",
    "\n",
    "    # Aggiunta 2: cerca anche nelle eventuali sottocartelle\n",
    "    for href in links:\n",
    "        if href.endswith('/'):  # Ã¨ una cartella\n",
    "            sub_url = urljoin(base_url + \"/\", href)\n",
    "            sub_links = list_links(sub_url, username, password)\n",
    "            for sub_href in sub_links:\n",
    "                if sub_href.lower().endswith(('.wav', '.flac')):\n",
    "                    urls.append(urljoin(sub_url, sub_href))\n",
    "\n",
    "    return urls\n",
    "\n",
    "def analyze_all(file_urls, username, password, model, model_type, csv_name):\n",
    "    \"\"\"\n",
    "    Analizza direttamente una lista di URL di file audio.\n",
    "    Non scandisce cartelle, ma lavora su singoli path.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for url in file_urls:\n",
    "        print(f\"\\nAnalizzo: {url}\")\n",
    "        try:\n",
    "            loss = analyze_in_memory(url, username, password, model)\n",
    "            status = \"Anomalo\" if loss > threshold else \"Normale\"\n",
    "            print(f\" --> Risultato: {status} (MSE: {loss:.6f})\")\n",
    "            results.append((url, status, loss))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore su {url}: {e}\")\n",
    "            results.append((url, \"Errore\", None))\n",
    "\n",
    "    # Filtra solo anomalie\n",
    "    anomalies = [r for r in results if r[1] == \"Anomalo\"]\n",
    "\n",
    "    # Estrai nome file (senza estensione) per il CSV\n",
    "    try:\n",
    "        file_name = file_urls[0].split(\"/\")[-1].split(\".\")[0]\n",
    "    except IndexError:\n",
    "        file_name = \"unknown\"\n",
    "\n",
    "    csv_filename = f\"esiti_{csv_name}/{model_type}_esito_{file_name}.csv\"\n",
    "\n",
    "    # Salva CSV\n",
    "    try:\n",
    "        with open(csv_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"url\", \"status\", \"loss\"])\n",
    "            for url, status, loss in anomalies:\n",
    "                loss_str = f\"{loss:.6f}\" if loss is not None else \"\"\n",
    "                writer.writerow([url, status, loss_str])\n",
    "        print(f\"\\nSalvati {len(anomalies)} file anomali in '{csv_filename}'\")\n",
    "\n",
    "        # Inserisce intestazione personalizzata\n",
    "        prepend_metadata_to_csv(\n",
    "            csv_filename=csv_filename,\n",
    "            modello=\"NS V1.01S\",\n",
    "            tipo_file=\"FLAC\",\n",
    "            durata_segmento=\"1\",\n",
    "            verificato1=\"0\",\n",
    "            verificato2=\"1\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio di {csv_filename}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def prepend_metadata_to_csv(csv_filename, modello, tipo_file, durata_segmento, verificato1, verificato2):\n",
    "    header = [\"modello\", \"tipo_file\", \"durata_segmento\", \"verificato\", \"verificato\"]\n",
    "    metadata = [modello, tipo_file, durata_segmento, verificato1, verificato2]\n",
    "\n",
    "    try:\n",
    "        with open(csv_filename, mode='r') as original:\n",
    "            original_lines = original.readlines()\n",
    "\n",
    "        with open(csv_filename, mode='w', newline='') as modified:\n",
    "            writer = csv.writer(modified)\n",
    "            writer.writerow(header)\n",
    "            writer.writerow(metadata)\n",
    "            modified.writelines(original_lines)\n",
    "\n",
    "        print(f\"Meta-intestazione inserita in '{csv_filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'inserimento della meta-intestazione in {csv_filename}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "###=== ESECUZIONE ===###\n",
    "# Carica il tuo modello\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"results_1s/best_model_1s.pth\"\n",
    "model = NS_1()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model_type = '1s'\n",
    "csv_name = \"0808\"\n",
    "\n",
    "\n",
    "base_urls = [\n",
    "    \"https://lys-ai.it/recordings/8c69c0b3-ae12-4552-9b11-0aaa0304a06d/recordings/2025-231/device/RSP1-MIC1/RSP1-MIC1_20250819_125515.wav\"]\n",
    "\n",
    "username = \"milone\"\n",
    "password = \"Neurone-pc\"\n",
    "\n",
    "# Analizza tutti i file per ogni cartella\n",
    "analyze_all(base_urls, username, password, model, model_type, csv_name)\n"
   ],
   "id": "590eebcadf81e606",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizzo: https://lys-ai.it/recordings/8c69c0b3-ae12-4552-9b11-0aaa0304a06d/recordings/2025-231/device/RSP1-MIC1/RSP1-MIC1_20250819_125515.wav\n",
      " --> Risultato: Anomalo (MSE: 0.003391)\n",
      "\n",
      "Salvati 1 file anomali in 'esiti_0808/1s_esito_RSP1-MIC1_20250819_125515.csv'\n",
      "Meta-intestazione inserita in 'esiti_0808/1s_esito_RSP1-MIC1_20250819_125515.csv'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T23:42:44.321984Z",
     "start_time": "2025-08-19T23:42:44.316605Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "72575bae3ba4bc94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T23:51:11.093476Z",
     "start_time": "2025-08-19T23:51:08.875975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_audio(file_like, target_length=seg_len):\n",
    "    waveform, sr = torchaudio.load(file_like)\n",
    "    if sr != sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    original_length = waveform.shape[1]  # Lunghezza in campioni\n",
    "\n",
    "    # Padding o trimming\n",
    "    if original_length > target_length:\n",
    "        waveform = waveform[:, :target_length]\n",
    "        original_length = target_length\n",
    "    else:\n",
    "        pad_len = target_length - original_length\n",
    "        waveform = F.pad(waveform, (0, pad_len))\n",
    "\n",
    "    return waveform.squeeze(0), original_length  # [160000], valore reale\n",
    "\n",
    "\n",
    "def run_inference(model, audio_tensor, original_length, threshold=threshold):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    model.transform_tf = model.transform_tf.to(device)\n",
    "\n",
    "    audio_tensor = audio_tensor.unsqueeze(0).to(device)  # [1, 160000]\n",
    "    feature_vector = model.preprocessing(audio_tensor)   # [1, T, 640]\n",
    "\n",
    "    # Calcolo numero di frame reali\n",
    "    hop_length = model.transform_tf.hop_length\n",
    "    real_t_bins = 1 + (original_length // hop_length)\n",
    "    real_vector_array_size = real_t_bins - model.frames + 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded = model.encoder(feature_vector)\n",
    "        bottleneck = model.bottleneck(encoded)\n",
    "        reconstructed = model.decoder(bottleneck)\n",
    "\n",
    "    # Taglio alla lunghezza effettiva in feature (T)\n",
    "    feature_vector = feature_vector[:, :real_vector_array_size, :]\n",
    "    reconstructed = reconstructed[:, :real_vector_array_size, :]\n",
    "\n",
    "    # Calcolo errore\n",
    "    loss = F.mse_loss(reconstructed, feature_vector).item()\n",
    "    return feature_vector.cpu(), reconstructed.cpu(), loss\n",
    "\n",
    "\n",
    "def analyze_in_memory(url, username, password, model):\n",
    "    resp = requests.get(url, auth=HTTPBasicAuth(username, password), stream=True)\n",
    "    resp.raise_for_status()\n",
    "    audio_data = io.BytesIO(resp.content)\n",
    "\n",
    "    waveform, real_samples = load_audio(audio_data)\n",
    "    _, _, loss = run_inference(model, waveform, real_samples)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def list_links(url, username, password):\n",
    "    print(f\"Listo i link da: {url}\")\n",
    "    resp = requests.get(url, auth=HTTPBasicAuth(username, password))\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "    print(f\"Link trovati: {links}\")\n",
    "    return links\n",
    "\n",
    "\n",
    "def gather_audio_urls(base_url, username, password):\n",
    "    urls = []\n",
    "    links = list_links(base_url, username, password)\n",
    "\n",
    "    # Cerca direttamente i file FLAC/WAV in base_url\n",
    "    for href in links:\n",
    "        if href.lower().endswith(('.wav', '.flac')):\n",
    "            urls.append(urljoin(base_url + \"/\", href))\n",
    "\n",
    "    # Cerca anche nelle sottocartelle\n",
    "    for href in links:\n",
    "        if href.endswith('/'):  # Ã¨ una cartella\n",
    "            sub_url = urljoin(base_url + \"/\", href)\n",
    "            sub_links = list_links(sub_url, username, password)\n",
    "            for sub_href in sub_links:\n",
    "                if sub_href.lower().endswith(('.wav', '.flac')):\n",
    "                    urls.append(urljoin(sub_url, sub_href))\n",
    "\n",
    "    return urls\n",
    "\n",
    "\n",
    "# ð¹ Funzione SFTP aggiornata\n",
    "def upload_via_sftp(local_file, remote_path, hostname, username, password, port=2200):\n",
    "    try:\n",
    "        transport = paramiko.Transport((hostname, port))\n",
    "        transport.connect(username=username, password=password)\n",
    "        sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "\n",
    "        # Creazione ricorsiva delle cartelle remote\n",
    "        remote_dir = os.path.dirname(remote_path)\n",
    "        dirs = remote_dir.strip(\"/\").split(\"/\")\n",
    "        current = \"\"\n",
    "        for d in dirs:\n",
    "            current += \"/\" + d\n",
    "            try:\n",
    "                sftp.stat(current)\n",
    "            except FileNotFoundError:\n",
    "                sftp.mkdir(current)\n",
    "\n",
    "        sftp.put(local_file, remote_path)\n",
    "        sftp.close()\n",
    "        transport.close()\n",
    "        print(f\"â File caricato via SFTP su {remote_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"â Errore SFTP: {e}\")\n",
    "\n",
    "\n",
    "def analyze_all(file_urls, username, password, model, model_type, txt_name,\n",
    "                remote_folder_path=None, remote_host=None, port=2200):\n",
    "    results = []\n",
    "    for url in file_urls:\n",
    "        print(f\"\\nAnalizzo: {url}\")\n",
    "        try:\n",
    "            loss = analyze_in_memory(url, username, password, model)\n",
    "            status = \"Anomalo\" if loss > threshold else \"Normale\"\n",
    "            print(f\" --> Risultato: {status} (MSE: {loss:.6f})\")\n",
    "            results.append((url, status, loss))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore su {url}: {e}\")\n",
    "            results.append((url, \"Errore\", None))\n",
    "\n",
    "    anomalies = [r for r in results if r[1] == \"Anomalo\"]\n",
    "\n",
    "    try:\n",
    "        file_name = file_urls[0].split(\"/\")[-1].split(\".\")[0]\n",
    "    except IndexError:\n",
    "        file_name = \"unknown\"\n",
    "\n",
    "    txt_filename = f\"esiti_{txt_name}/{model_type}_esito_{file_name}.txt\"\n",
    "\n",
    "    # ð¹ Salva in locale come TXT\n",
    "    os.makedirs(f\"esiti_{txt_name}\", exist_ok=True)\n",
    "    with open(txt_filename, mode='w', encoding=\"utf-8\") as file:\n",
    "        file.write(\"### META-INFORMAZIONI ###\\n\")\n",
    "        file.write(\"modello: NS V1.01S\\n\")\n",
    "        file.write(\"tipo_file: FLAC\\n\")\n",
    "        file.write(\"durata_segmento: 1\\n\")\n",
    "        file.write(\"verificato1: 0\\n\")\n",
    "        file.write(\"verificato2: 1\\n\")\n",
    "        file.write(\"\\n### RISULTATI ###\\n\")\n",
    "        for url, status, loss in anomalies:\n",
    "            loss_str = f\"{loss:.6f}\" if loss is not None else \"N/A\"\n",
    "            file.write(f\"url: {url}\\nstatus: {status}\\nloss: {loss_str}\\n\\n\")\n",
    "\n",
    "    print(f\"\\nTXT salvato in locale: {txt_filename}\")\n",
    "\n",
    "    # ð¹ Upload anche su server via SFTP\n",
    "    if remote_folder_path and remote_host:\n",
    "        remote_txt_path = f\"{remote_folder_path}/{os.path.basename(txt_filename)}\"\n",
    "        upload_via_sftp(\n",
    "            local_file=txt_filename,\n",
    "            remote_path=remote_txt_path,\n",
    "            hostname=remote_host,\n",
    "            username=username,\n",
    "            password=password,\n",
    "            port=port\n",
    "        )\n",
    "\n",
    "\n",
    "###=== ESECUZIONE ===###\n",
    "# Carica il tuo modello\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"results_1s/best_model_1s.pth\"\n",
    "model = NS_1()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model_type = '1s'\n",
    "txt_name = \"0808\"\n",
    "\n",
    "base_urls = [\n",
    "    \"https://lys-ai.it/recordings/8c69c0b3-ae12-4552-9b11-0aaa0304a06d/recordings/2025-231/device/RSP1-MIC1/RSP1-MIC1_20250819_125515.wav\"\n",
    "]\n",
    "\n",
    "username = \"milone\"\n",
    "password = \"Neurone-pc\"\n",
    "\n",
    "# Analizza e salva anche su server (via SFTP)\n",
    "analyze_all(\n",
    "    base_urls, username, password, model, model_type, txt_name,\n",
    "    remote_folder_path=\"/mnt/BB-S_STORAGE/8c69c0b3-ae12-4552-9b11-0aaa0304a06d/recordings/2025-231/device/RSP1-MIC1/esiti_txt\",\n",
    "    remote_host=\"151.14.46.173\",\n",
    "    port=2200\n",
    ")"
   ],
   "id": "cc5dc5d14e647a0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizzo: https://lys-ai.it/recordings/8c69c0b3-ae12-4552-9b11-0aaa0304a06d/recordings/2025-231/device/RSP1-MIC1/RSP1-MIC1_20250819_125515.wav\n",
      " --> Risultato: Anomalo (MSE: 0.003391)\n",
      "\n",
      "TXT salvato in locale: esiti_0808/1s_esito_RSP1-MIC1_20250819_125515.txt\n",
      "â File caricato via SFTP su /mnt/BB-S_STORAGE/8c69c0b3-ae12-4552-9b11-0aaa0304a06d/recordings/2025-231/device/RSP1-MIC1/esiti_txt/1s_esito_RSP1-MIC1_20250819_125515.txt\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3baf3ae1d8b7dd35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
